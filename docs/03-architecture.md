# 3. Architecture

This document describes the system architectureâ€”the major components and how they interact.

## ğŸ—ï¸ System Layers

The system has three main layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAYER 1: MCP INTERFACE                       â”‚
â”‚                                                                 â”‚
â”‚  What the AI sees:                                              â”‚
â”‚  â€¢ One tool: run_python                                         â”‚
â”‚  â€¢ One resource: code-execution-capabilities                    â”‚
â”‚                                                                 â”‚
â”‚  The AI sends Python code, gets back output.                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAYER 2: BRIDGE ORCHESTRATION                â”‚
â”‚                                                                 â”‚
â”‚  What happens behind the scenes:                                â”‚
â”‚  â€¢ MCPBridge: Main coordinator                                  â”‚
â”‚  â€¢ SandboxInvocation: Per-execution context                     â”‚
â”‚  â€¢ PersistentMCPClient: Connection to each MCP server           â”‚
â”‚  â€¢ RootlessContainerSandbox: Container management               â”‚
â”‚                                                                 â”‚
â”‚  Manages the whole execution lifecycle.                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAYER 3: ISOLATED EXECUTION                  â”‚
â”‚                                                                 â”‚
â”‚  Where code actually runs:                                      â”‚
â”‚  â€¢ Docker/Podman container                                      â”‚
â”‚  â€¢ Generated entrypoint.py                                      â”‚
â”‚  â€¢ MCP proxies and runtime helpers                              â”‚
â”‚                                                                 â”‚
â”‚  Complete isolation from the host.                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Component Breakdown

### 1. MCP Server Interface

The bridge is itself an MCP server. When Claude connects to it, it sees:

**Tools:**
```python
{
    "name": "run_python",
    "description": "Execute Python code in a sandboxed environment...",
    "inputSchema": {
        "properties": {
            "code": {"type": "string"},
            "servers": {"type": "array", "items": {"type": "string"}},
            "timeout": {"type": "integer", "default": 30}
        },
        "required": ["code"]
    }
}
```

**Resources:**
```python
{
    "uri": "resource://mcp-server-code-execution-mode/capabilities",
    "name": "code-execution-capabilities",
    "description": "Capability overview and helper reference"
}
```

### 2. MCPBridge Class

The central coordinator. Key responsibilities:

| Responsibility | What It Does |
|----------------|--------------|
| **Server Discovery** | Scans config files to find MCP servers |
| **Server Loading** | Starts `PersistentMCPClient` for each server |
| **Metadata Caching** | Caches tool schemas to avoid repeated queries |
| **Code Execution** | Creates `SandboxInvocation`, runs code, returns results |
| **RPC Routing** | Forwards sandbox RPC requests to real MCP servers |

```python
# Simplified structure
class MCPBridge:
    def __init__(self):
        self.sandbox = RootlessContainerSandbox()  # Container manager
        self.servers = {}      # MCPServerInfo objects
        self.clients = {}      # PersistentMCPClient objects
        self._aliases = {}     # Server name â†’ alias mapping
        self._server_metadata_cache = {}
        # Note: _cleanup_stale_ipc_dirs() runs on init to prune old IPC
        # directories using LRU, keeping max 50
        
    async def execute_code(self, code, servers, timeout):
        # 1. Load requested MCP servers
        # 2. Create SandboxInvocation context
        # 3. Run code in container
        # 4. Handle RPC calls
        # 5. Return result
```

### 3. RootlessContainerSandbox Class

Manages the container lifecycle:

```python
class RootlessContainerSandbox:
    def __init__(self):
        self.runtime = detect_runtime()  # 'podman' or 'docker'
        self.image = "python:3.14-slim"
        self._process = None  # The running container process
        
    def _render_entrypoint(self, servers_metadata, discovered_servers):
        # Generate the ~600 line entrypoint.py
        
    async def _ensure_started(self, ...):
        # Start container if not running
        
    async def execute(self, code, ...):
        # Send code to running container
```

**Container configuration:**
```bash
podman run \
    --rm \
    --interactive \
    --network none \                    # No network access
    --read-only \                       # Read-only filesystem
    --pids-limit 128 \                  # Max 128 processes
    --memory 512m \                     # Max 512MB RAM
    --tmpfs /tmp:rw,noexec,size=64m \   # Writable /tmp
    --tmpfs /workspace:rw,size=128m \   # Writable workspace
    --security-opt no-new-privileges \  # Can't escalate
    --cap-drop ALL \                    # No capabilities
    --user 65534:65534 \                # Nobody user
    python:3.14-slim python3 -u /ipc/entrypoint.py
```

### 4. PersistentMCPClient Class

Maintains connections to real MCP servers:

```python
class PersistentMCPClient:
    def __init__(self, server_info: MCPServerInfo):
        self.server_info = server_info  # command, args, env
        self._session = None
        
    async def start(self):
        # Start the MCP server process
        # Establish stdio communication
        # Initialize MCP session
        
    async def list_tools(self):
        # Get available tools from server
        
    async def call_tool(self, name, arguments):
        # Call a specific tool
```

### 5. SandboxInvocation Class

Per-execution context manager:

```python
class SandboxInvocation:
    def __init__(self, bridge, active_servers):
        self.bridge = bridge
        self.active_servers = active_servers
        
    async def __aenter__(self):
        # 1. Gather server metadata
        # 2. Create temp directory for IPC
        # 3. Set up volume mounts
        # 4. Set environment variables
        
    async def handle_rpc(self, request):
        # Route RPC requests to appropriate MCP server
        # Supported types: list_servers, call_tool, list_tools,
        #                  query_tool_docs, search_tool_docs
```

---

## ğŸ”€ Data Flow

Here's how data flows through the system when the AI calls `run_python`:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DATA FLOW                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. AI calls run_python
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
   
   {
     "name": "run_python",
     "arguments": {
       "code": "weather = await mcp_weather.get_weather('NYC')\nprint(weather)",
       "servers": ["weather"],
       "timeout": 30
     }
   }

2. Bridge validates input
   â”‚
   â”œâ”€â”€ Check code is non-empty string
   â”œâ”€â”€ Check servers is a list
   â””â”€â”€ Check timeout is valid integer

3. Bridge loads MCP servers
   â”‚
   â””â”€â”€ For each server in "servers":
       â”œâ”€â”€ Find config (from discovery)
       â”œâ”€â”€ Start PersistentMCPClient (if not running)
       â””â”€â”€ Cache metadata

4. Create SandboxInvocation
   â”‚
   â”œâ”€â”€ Collect server metadata (tools, schemas)
   â”œâ”€â”€ Create temp directory (/ipc)
   â”œâ”€â”€ Set up volume mounts
   â””â”€â”€ Set environment variables

5. Ensure container is running
   â”‚
   â”œâ”€â”€ If not started:
   â”‚   â”œâ”€â”€ Generate entrypoint.py
   â”‚   â”œâ”€â”€ Write to /ipc/entrypoint.py
   â”‚   â””â”€â”€ Start container process
   â””â”€â”€ If already started:
       â””â”€â”€ Reuse existing container

6. Send code to container
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
   
   {"type": "execute", "code": "weather = await mcp_weather.get_weather('NYC')..."}

7. Container executes code
   â”‚
   â”œâ”€â”€ Parse with async support
   â”œâ”€â”€ Execute in global namespace
   â”‚
   â”‚   Code calls: mcp_weather.get_weather('NYC')
   â”‚              â†“
   â”‚   Proxy intercepts, sends RPC:
   â”‚   {"type": "rpc_request", "id": 1, "payload": {"type": "call_tool", ...}}
   â”‚
   â””â”€â”€ Wait for RPC response

8. Bridge receives RPC request
   â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Bridge routes to PersistentMCPClient for "weather"
   Calls real weather server
   Gets response

9. Bridge sends RPC response
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
   
   {"type": "rpc_response", "id": 1, "payload": {"result": {"temp": 72, ...}}}

10. Container receives response, continues execution
    â”‚
    â”œâ”€â”€ print(weather) â†’ {"type": "stdout", "data": "{'temp': 72, ...}"}
    â””â”€â”€ Done â†’ {"type": "execution_done"}

11. Bridge collects output
    â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Aggregates stdout, stderr
    Builds response payload

12. Bridge returns to AI
    â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    {
      "content": [{"type": "text", "text": "{'temp': 72, ...}"}],
      "structuredContent": {"status": "success", "stdout": [...]}
    }
```

---

## ğŸ“ File Structure

```
mcp_server_code_execution_mode.py
â”œâ”€â”€ Constants & Configuration
â”‚   â”œâ”€â”€ DEFAULT_IMAGE, DEFAULT_TIMEOUT, etc.
â”‚   â””â”€â”€ CONFIG_SOURCES (where to find MCP configs)
â”‚
â”œâ”€â”€ Helper Functions
â”‚   â”œâ”€â”€ _render_compact_output()
â”‚   â”œâ”€â”€ _build_tool_response()
â”‚   â””â”€â”€ detect_runtime()
â”‚
â”œâ”€â”€ Data Classes
â”‚   â”œâ”€â”€ SandboxResult
â”‚   â””â”€â”€ MCPServerInfo
â”‚
â”œâ”€â”€ Core Classes
â”‚   â”œâ”€â”€ PersistentMCPClient
â”‚   â”œâ”€â”€ RootlessContainerSandbox
â”‚   â”‚   â””â”€â”€ _render_entrypoint() (generates 600-line script)
â”‚   â”œâ”€â”€ SandboxInvocation
â”‚   â””â”€â”€ MCPBridge
â”‚
â”œâ”€â”€ MCP Server Setup
â”‚   â”œâ”€â”€ @app.list_tools()
â”‚   â”œâ”€â”€ @app.list_resources()
â”‚   â”œâ”€â”€ @app.read_resource()
â”‚   â””â”€â”€ @app.call_tool()
â”‚
â””â”€â”€ main() entrypoint
```

---

## ğŸ”‘ Design Decisions

### Why One Tool (`run_python`) Instead of Many?

**Problem:** Traditional MCP loads all tool schemas into context (30,000+ tokens for 100 tools).

**Solution:** One tool that gives the AI the power to discover and call tools programmatically.

**Trade-off:** The AI must write Python code, but this is actually a benefitâ€”LLMs are very good at generating code, and code can express complex logic (loops, conditions) that individual tool calls cannot.

### Why Containers?

**Options considered:**
1. **No isolation** - Too dangerous for untrusted code
2. **VM-based** - Too slow and resource-heavy
3. **Language-level (like Node.js vm)** - Not secure enough
4. **Containers** - Good balance of security and performance

**Containers provide:**
- Strong isolation (namespace separation)
- Lightweight (shared kernel)
- Configurable restrictions (network, filesystem, resources)

### Why Persistent Containers?

Instead of starting a new container for each execution, we keep one running:

| Approach | Cold Start | State Persistence | Resource Usage |
|----------|------------|-------------------|----------------|
| New container each time | ~1-2 seconds | None | High |
| Persistent container | ~0 seconds | Variables persist | Lower |

### Why stdio Communication?

```
Host                    Container
  â”‚                        â”‚
  â”œâ”€â”€ stdin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚                        â”‚
  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ stdout â”€â”€â”€â”€â”€â”¤
  â”‚                        â”‚
  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ stderr â”€â”€â”€â”€â”€â”¤
```

**Benefits:**
- Simple and universal
- No networking required
- Easy to implement in any language
- Built-in backpressure

---

## Next Steps

â†’ [Execution Flow](04-execution-flow.md) - Walk through a complete execution
